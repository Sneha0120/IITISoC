# IITISoC Instrument Classification

Build a voice classifier that will identify the name of the instrument from its voice sample. Try to include as many instruments as possible in the classification output.

The classification of instruments is a highly valuable work since it has the potential to allow the extraction of useful data, which in turn could help with tasks like music genre classification and instrument search. Our model is based on the CNN deep learning model. We first take the input as an audio file then preprocess it into mfcc(Mel-frequency cepstral coefficients) data and then finally convert it into a spectogram, upon this preprocessed data the CNN model acts and predicts the output for the new data. We have a dataset of 9478 files distributed unequally among  41 classes, Due to the restricted time of the project, we scoped down the number of instruments to detect five instruments: 'Saxophone', 'Acoustic_guitar', 'Bass_drum', 'Clarinet',' Violin_or_fiddle', having 300 files of each. We have used the library librosa for audio classification.  Our model architecture consists of a convolutional neural network which performs the classification. Our data consists in audio streams which we pre-process to extract the mel-spectogram. The input of the model is thus the mel-spectogram, and the output is an index corresponding to the predicted class. We have used adam optimizer. We obtained a precision of 90.7%, a recall of 89.1%, and a F1-score of 89.9%. We discussed some of the challenges associated with the convolutional approach. We concluded that despite the challenges, CNNs remain a promising approach to this problem.


Dataset can be downloaded: [Click Here](https://drive.google.com/drive/folders/1SPIGJm7NaMTcV8Pw0pnCwYTYEHakyrnt?usp=sharing)
